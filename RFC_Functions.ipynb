{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from datetime import timedelta\n",
    "import pandas_datareader as pdr\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import bs4 as bs\n",
    "import requests\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats import mstats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import RandomizedSearchCV, validation_curve, TimeSeriesSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import yfinance as yf\n",
    "import json\n",
    "import time\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(user_stocks):\n",
    "    \n",
    "    output_dict = {}\n",
    "    no_data = []\n",
    "    \n",
    "    Target_variables = ['SMA_ratio','ATR_8','ATR_20','ATR_Ratio', 'SMA_Volume_Ratio',\n",
    "                       'ADX_8','ADX_20','Stochastic_8','Stochastic_20','Stochastic_Ratio',\n",
    "                      'RSI_8','RSI_20','RSI_ratio','MACD', 'Middleband']\n",
    "    \n",
    "    sector_dict = {'Technology': 0,\n",
    "                     'Healthcare': 1,\n",
    "                     'Financial Services': 2,\n",
    "                     'Real Estate': 3,\n",
    "                     'Consumer Cyclical': 4,\n",
    "                     'Industrials': 5,\n",
    "                     'Communication Services': 6,\n",
    "                     'Consumer Defensive': 7,\n",
    "                     'Energy': 8,\n",
    "                     'Basic Materials': 9,\n",
    "                     'Utilities': 10,\n",
    "                     'Misc': 11}\n",
    "    def Wilder(data, periods):\n",
    "        start = np.where(~np.isnan(data))[0][0] #Check if nans present in beginning\n",
    "        Wilder = np.array([np.nan]*len(data))\n",
    "        Wilder[start+periods-1] = data[start:(start+periods)].mean() #Simple Moving Average\n",
    "        for i in range(start+periods,len(data)):\n",
    "            Wilder[i] = (Wilder[i-1]*(periods-1) + data[i])/periods #Wilder Smoothing\n",
    "        return(Wilder)\n",
    "\n",
    "    #Extract data from Yahoo Finance\n",
    "    for ticker in user_stocks:\n",
    "        user_data = pd.DataFrame()\n",
    "        test_data = pd.DataFrame()\n",
    "        try:\n",
    "            print(ticker)\n",
    "            test_data = pdr.get_data_yahoo(ticker, start = (dt.date.today() - timedelta(days=60)), end = (dt.date.today() - timedelta(days=1)))\n",
    "            test_data['Symbol'] = ticker\n",
    "            user_data = user_data.append(test_data)\n",
    "            clear_output(wait = True)\n",
    "        except:\n",
    "            no_data.append(ticker)\n",
    "        \n",
    "        if len(no_data) != 0:\n",
    "            print(\"No data obtained for provided ticker\")\n",
    "            return 0\n",
    "\n",
    "        clear_output(wait = True)\n",
    "        \n",
    "        #################################\n",
    "        user_data['Return'] = user_data['Close'].pct_change()\n",
    "        user_data.reset_index(inplace=True)\n",
    "        \n",
    "        #################################\n",
    "        \n",
    "        # Calculating SMA for 14 day period \n",
    "        \n",
    "        user_data['SMA_8'] = user_data['Close'].transform(lambda x: x.rolling(window = 8).mean())\n",
    "        user_data['SMA_20'] = user_data['Close'].transform(lambda x: x.rolling(window = 20).mean())\n",
    "        user_data['SMA_ratio'] = user_data['SMA_20'] / user_data['SMA_8']\n",
    "        user_data.set_index('Date', inplace=True)\n",
    "        \n",
    "        #################################\n",
    "        \n",
    "        # SMA Volume Ratio\n",
    "        \n",
    "        user_data['SMA8_Volume'] = user_data.groupby('Symbol')['Volume'].transform(lambda x: x.rolling(window = 8).mean())\n",
    "        user_data['SMA20_Volume'] = user_data.groupby('Symbol')['Volume'].transform(lambda x: x.rolling(window = 20).mean())\n",
    "        user_data['SMA_Volume_Ratio'] = user_data['SMA8_Volume']/user_data['SMA20_Volume']\n",
    "        \n",
    "        #################################\n",
    "        \n",
    "        # ATR\n",
    "        user_data['prev_close'] = user_data.groupby('Symbol')['Close'].shift(1)\n",
    "        user_data['TR'] = np.maximum((user_data['High'] - user_data['Low']), \n",
    "                             np.maximum(abs(user_data['High'] - user_data['prev_close']), \n",
    "                             abs(user_data['prev_close'] - user_data['Low'])))\n",
    "        for i in user_data['Symbol'].unique():\n",
    "            TR_data = user_data[user_data.Symbol == i].copy()\n",
    "            user_data.loc[user_data.Symbol==i,'ATR_8'] = Wilder(TR_data['TR'], 8)\n",
    "            user_data.loc[user_data.Symbol==i,'ATR_20'] = Wilder(TR_data['TR'], 20)\n",
    "\n",
    "        user_data['ATR_Ratio'] = user_data['ATR_8'] / user_data['ATR_20']\n",
    "        \n",
    "        #################################\n",
    "        \n",
    "        #ADX\n",
    "        user_data['prev_high'] = user_data.groupby('Symbol')['High'].shift(1)\n",
    "        user_data['prev_low'] = user_data.groupby('Symbol')['Low'].shift(1)\n",
    "\n",
    "        user_data['+DM'] = np.where(~np.isnan(user_data.prev_high),\n",
    "                                   np.where((user_data['High'] > user_data['prev_high']) & \n",
    "                 (((user_data['High'] - user_data['prev_high']) > (user_data['prev_low'] - user_data['Low']))), \n",
    "                                                                          user_data['High'] - user_data['prev_high'], \n",
    "                                                                          0),np.nan)\n",
    "\n",
    "        user_data['-DM'] = np.where(~np.isnan(user_data.prev_low),\n",
    "                                   np.where((user_data['prev_low'] > user_data['Low']) & \n",
    "                 (((user_data['prev_low'] - user_data['Low']) > (user_data['High'] - user_data['prev_high']))), \n",
    "                                            user_data['prev_low'] - user_data['Low'], \n",
    "                                            0),np.nan)\n",
    "\n",
    "        for i in user_data['Symbol'].unique():\n",
    "            ADX_data = user_data[user_data.Symbol == i].copy()\n",
    "            user_data.loc[user_data.Symbol==i,'+DM_8'] = Wilder(ADX_data['+DM'], 8)\n",
    "            user_data.loc[user_data.Symbol==i,'-DM_8'] = Wilder(ADX_data['-DM'], 8)\n",
    "            user_data.loc[user_data.Symbol==i,'+DM_20'] = Wilder(ADX_data['+DM'], 20)\n",
    "            user_data.loc[user_data.Symbol==i,'-DM_20'] = Wilder(ADX_data['-DM'], 20)\n",
    "\n",
    "        user_data['+DI_8'] = (user_data['+DM_8']/user_data['ATR_8'])*100\n",
    "        user_data['-DI_8'] = (user_data['-DM_8']/user_data['ATR_8'])*100\n",
    "        user_data['+DI_20'] = (user_data['+DM_20']/user_data['ATR_20'])*100\n",
    "        user_data['-DI_20'] = (user_data['-DM_20']/user_data['ATR_20'])*100\n",
    "\n",
    "        user_data['DX_8'] = (np.round(abs(user_data['+DI_8'] - user_data['-DI_8'])/(user_data['+DI_8'] + user_data['-DI_8']) * 100))\n",
    "\n",
    "        user_data['DX_20'] = (np.round(abs(user_data['+DI_20'] - user_data['-DI_20'])/(user_data['+DI_20'] + user_data['-DI_20']) * 100))\n",
    "\n",
    "        for i in user_data['Symbol'].unique():\n",
    "            ADX_data = user_data[user_data.Symbol == i].copy()\n",
    "            user_data.loc[user_data.Symbol==i,'ADX_8'] = Wilder(ADX_data['DX_8'], 8)\n",
    "            user_data.loc[user_data.Symbol==i,'ADX_20'] = Wilder(ADX_data['DX_20'], 20)\n",
    "\n",
    "            \n",
    "        ################################\n",
    "        \n",
    "        #Stochastic Oscillators\n",
    "        user_data['Lowest_8D'] = user_data.groupby('Symbol')['Low'].transform(lambda x: x.rolling(window = 8).min())\n",
    "        user_data['High_8D'] = user_data.groupby('Symbol')['High'].transform(lambda x: x.rolling(window = 8).max())\n",
    "        user_data['Lowest_20D'] = user_data.groupby('Symbol')['Low'].transform(lambda x: x.rolling(window = 20).min())\n",
    "        user_data['High_20D'] = user_data.groupby('Symbol')['High'].transform(lambda x: x.rolling(window = 20).max())\n",
    "\n",
    "        user_data['Stochastic_8'] = ((user_data['Close'] - user_data['Lowest_8D'])/(user_data['High_8D'] - user_data['Lowest_8D']))*100\n",
    "        user_data['Stochastic_20'] = ((user_data['Close'] - user_data['Lowest_20D'])/(user_data['High_20D'] - user_data['Lowest_20D']))*100\n",
    "\n",
    "        user_data['Stochastic_%D_8'] = user_data['Stochastic_8'].rolling(window = 8).mean()\n",
    "        user_data['Stochastic_%D_20'] = user_data['Stochastic_8'].rolling(window = 20).mean()\n",
    "\n",
    "        user_data['Stochastic_Ratio'] = user_data['Stochastic_%D_8']/user_data['Stochastic_%D_20']\n",
    "\n",
    "        ################################\n",
    "        \n",
    "        #RSI \n",
    "\n",
    "        user_data['Diff'] = user_data.groupby('Symbol')['Close'].transform(lambda x: x.diff())\n",
    "        user_data['Up'] = user_data['Diff']\n",
    "        user_data.loc[(user_data['Up']<0), 'Up'] = 0\n",
    "\n",
    "        user_data['Down'] = user_data['Diff']\n",
    "        user_data.loc[(user_data['Down']>0), 'Down'] = 0 \n",
    "        user_data['Down'] = abs(user_data['Down'])\n",
    "\n",
    "        user_data['avg_8up'] = user_data.groupby('Symbol')['Up'].transform(lambda x: x.rolling(window=8).mean())\n",
    "        user_data['avg_8down'] = user_data.groupby('Symbol')['Down'].transform(lambda x: x.rolling(window=8).mean())\n",
    "\n",
    "        user_data['avg_20up'] = user_data.groupby('Symbol')['Up'].transform(lambda x: x.rolling(window=20).mean())\n",
    "        user_data['avg_20down'] = user_data.groupby('Symbol')['Down'].transform(lambda x: x.rolling(window=20).mean())\n",
    "\n",
    "        user_data['RS_8'] = user_data['avg_8up'] / user_data['avg_8down']\n",
    "        user_data['RS_20'] = user_data['avg_20up'] / user_data['avg_20down']\n",
    "\n",
    "        user_data['RSI_8'] = 100 - (100/(1+user_data['RS_8']))\n",
    "        user_data['RSI_20'] = 100 - (100/(1+user_data['RS_20']))\n",
    "\n",
    "        user_data['RSI_ratio'] = user_data['RSI_8']/user_data['RSI_20']\n",
    "        \n",
    "        #################################\n",
    "        \n",
    "        #MACD\n",
    "\n",
    "        user_data['8Ewm'] = user_data.groupby('Symbol')['Close'].transform(lambda x: x.ewm(span=8, adjust=False).mean())\n",
    "        user_data['20Ewm'] = user_data.groupby('Symbol')['Close'].transform(lambda x: x.ewm(span=20, adjust=False).mean())\n",
    "        user_data['MACD'] = user_data['20Ewm'] - user_data['8Ewm']\n",
    "        \n",
    "        ##################################\n",
    "        \n",
    "        #Bollinger Bands\n",
    "\n",
    "        user_data['20MA'] = user_data.groupby('Symbol')['Close'].transform(lambda x: x.rolling(window=20).mean())\n",
    "        user_data['SD'] = user_data.groupby('Symbol')['Close'].transform(lambda x: x.rolling(window=20).std())\n",
    "        user_data['upperband'] = user_data['20MA'] + 2*user_data['SD']\n",
    "        user_data['lowerband'] = user_data['20MA'] - 2*user_data['SD']\n",
    "        user_data['Middleband'] = (user_data['upperband'] + user_data['lowerband'])/2\n",
    "        \n",
    "        ##################################\n",
    "        \n",
    "        #ROC\n",
    "        \n",
    "        user_data['RC'] = user_data.groupby('Symbol')['Close'].transform(lambda x: x.pct_change(periods = 20)) \n",
    "        \n",
    "        ##################################\n",
    "        \n",
    "        #Winsorize data\n",
    "        \n",
    "        for variable in Target_variables:\n",
    "            user_data.loc[:,variable] = mstats.winsorize(user_data.loc[:,variable], limits = [0.1,0.1])\n",
    "            \n",
    "        ##################################\n",
    "        \n",
    "        #Make Predictions based on the pickle files containing the models \n",
    "        \n",
    "        row= user_data.tail(1).fillna(0)\n",
    "        try:\n",
    "            sector = yf.Ticker(ticker).info['sector']\n",
    "        except:\n",
    "            sector = 'Misc'\n",
    "        rf_cv = pickle.load(open(os.getcwd() + f'\\\\RFC_2\\\\Sector_{sector_dict[sector]}', 'rb'))\n",
    "        best_rf = rf_cv.best_estimator_\n",
    "        X_test = row.reset_index()[Target_variables]\n",
    "        pred = best_rf.predict_proba(X_test)\n",
    "        output_dict[ticker] = pred[0][-1]\n",
    "        \n",
    "    output = {}\n",
    "    \n",
    "    print(\"Probability of stock price increase in 14 days from \" + (dt.date.today() - timedelta(days=1)).strftime('%Y-%m-%d') + \":\")\n",
    "    for ticker, prob in output_dict.items():\n",
    "        output[ticker] = prob\n",
    "        print(\"\\t\" + ticker + \" - \" + str(prob))\n",
    "    return output\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
